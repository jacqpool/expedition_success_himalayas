{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Himalayan Expedition Success - Data Cleaning\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Himalayan Database ©, consists of records for all expeditions in the Nepal Himalayas from 1905 through 2018. The database covers expeditions to more than 450 significant peaks, including Everest, Cho Oyu and Kangchenjunga. The database is published by The Himalayan Database ©, a non-profit organization. For more information go to http://himalayandatabase.com/index.html.\n",
    "\n",
    "### Datasets\n",
    "Two datasets are of interest: expeditions.csv and members.csv (http://himalayandatabase.com/downloads.html).\n",
    "\n",
    "###### peaks.csv\n",
    "This file contains information about each one of the more than 450 peaks, location, region, status, first ascent and more.\n",
    "\n",
    "###### expedions.csv\n",
    "This file contains information including date, peak, route, suplemantal oxygen, group size and sherpas.\n",
    "\n",
    "###### members.csv\n",
    "This file contains biographical information on each member in the expedition, including nationality, age, oxygen use, and success.\n",
    "\n",
    "### Outcome\n",
    "\n",
    "Nearly 10,000 expedition records and over 70,000 members records can then predict member success of a summitting a certain peak, during a certain time of year, with certain support mechanisms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set workspace\n",
    "\n",
    "# Set output charackters to 110 (not 79)\n",
    "pd.options.display.width = 110\n",
    "# To give multiple cell output. Not just the last command.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peaks dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (468, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Data columns (total 22 columns):\n",
      "peakid        468 non-null object\n",
      "pkname        468 non-null object\n",
      "pkname2       238 non-null object\n",
      "location      467 non-null object\n",
      "heightm       468 non-null int64\n",
      "heightf       468 non-null int64\n",
      "himal         468 non-null int64\n",
      "region        468 non-null int64\n",
      "open          468 non-null bool\n",
      "unlisted      468 non-null bool\n",
      "trekking      468 non-null bool\n",
      "trekyear      29 non-null float64\n",
      "restrict      270 non-null object\n",
      "phost         468 non-null int64\n",
      "pstatus       468 non-null int64\n",
      "pyear         325 non-null float64\n",
      "pseason       468 non-null int64\n",
      "pexpid        322 non-null object\n",
      "psmtdate      319 non-null object\n",
      "pcountry      325 non-null object\n",
      "psummiters    460 non-null object\n",
      "psmtnote      75 non-null object\n",
      "dtypes: bool(3), float64(2), int64(7), object(10)\n",
      "memory usage: 70.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load peaks as 'peaks_csv'\n",
    "peaks_csv = pd.read_csv('peaks.csv')\n",
    "print('Shape:', peaks_csv.shape)\n",
    "\n",
    "peaks_csv.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to the 'Himalayan Database Guide.pdf', the following features will not be included:\n",
    "\n",
    "pkname, pkname2 - The names of the peaks are not required for analysis, but can be inluded post-analysis.\n",
    "\n",
    "location - This field gives a long description of the expedition only. The locations are better captured with categorical data 'himal' and 'region'.\n",
    "\n",
    "heightf - Only 'heightm', the height in meters, are used.\n",
    "\n",
    "pseason, pexpid, psmtdate, pcountry, psummiters, psmnote - Information on the first ascent of a certain peak. Not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peakid</th>\n",
       "      <th>heightm</th>\n",
       "      <th>himal</th>\n",
       "      <th>region</th>\n",
       "      <th>open</th>\n",
       "      <th>unlisted</th>\n",
       "      <th>trekking</th>\n",
       "      <th>trekyear</th>\n",
       "      <th>restrict</th>\n",
       "      <th>phost</th>\n",
       "      <th>pstatus</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACHN</td>\n",
       "      <td>6055</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Opened in 2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGLE</td>\n",
       "      <td>6675</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Opened in 2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAD</td>\n",
       "      <td>6814</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMOT</td>\n",
       "      <td>6393</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Opened in 2002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMPG</td>\n",
       "      <td>5630</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Opened in 2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1953.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  peakid  heightm  himal  region  open  unlisted  trekking  trekyear        restrict  phost  pstatus   pyear\n",
       "0   ACHN     6055     17       7  True     False     False       NaN  Opened in 2014      1        2  2015.0\n",
       "1   AGLE     6675     19       2  True     False     False       NaN  Opened in 2014      1        1     NaN\n",
       "2   AMAD     6814     12       2  True     False     False       NaN             NaN      1        2  1961.0\n",
       "3   AMOT     6393      3       5  True     False     False       NaN  Opened in 2002      1        1     NaN\n",
       "4   AMPG     5630     12       2  True     False     False       NaN  Opened in 2002      1        2  1953.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Data columns (total 12 columns):\n",
      "peakid      468 non-null object\n",
      "heightm     468 non-null int64\n",
      "himal       468 non-null int64\n",
      "region      468 non-null int64\n",
      "open        468 non-null bool\n",
      "unlisted    468 non-null bool\n",
      "trekking    468 non-null bool\n",
      "trekyear    29 non-null float64\n",
      "restrict    270 non-null object\n",
      "phost       468 non-null int64\n",
      "pstatus     468 non-null int64\n",
      "pyear       325 non-null float64\n",
      "dtypes: bool(3), float64(2), int64(5), object(2)\n",
      "memory usage: 34.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heightm</th>\n",
       "      <th>himal</th>\n",
       "      <th>region</th>\n",
       "      <th>trekyear</th>\n",
       "      <th>phost</th>\n",
       "      <th>pstatus</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>468.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6656.653846</td>\n",
       "      <td>10.258547</td>\n",
       "      <td>3.820513</td>\n",
       "      <td>1918.758621</td>\n",
       "      <td>2.126068</td>\n",
       "      <td>1.707265</td>\n",
       "      <td>1983.510769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>571.898154</td>\n",
       "      <td>5.585948</td>\n",
       "      <td>2.150107</td>\n",
       "      <td>365.364168</td>\n",
       "      <td>1.514782</td>\n",
       "      <td>0.455505</td>\n",
       "      <td>23.674178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5407.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6235.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6559.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6911.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8850.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           heightm       himal      region     trekyear       phost     pstatus        pyear\n",
       "count   468.000000  468.000000  468.000000    29.000000  468.000000  468.000000   325.000000\n",
       "mean   6656.653846   10.258547    3.820513  1918.758621    2.126068    1.707265  1983.510769\n",
       "std     571.898154    5.585948    2.150107   365.364168    1.514782    0.455505    23.674178\n",
       "min    5407.000000    1.000000    1.000000    20.000000    1.000000    1.000000  1909.000000\n",
       "25%    6235.750000    5.000000    2.000000  1978.000000    1.000000    1.000000  1963.000000\n",
       "50%    6559.500000   11.000000    4.000000  1978.000000    1.000000    2.000000  1981.000000\n",
       "75%    6911.000000   15.000000    6.000000  2002.000000    4.000000    2.000000  2007.000000\n",
       "max    8850.000000   20.000000    7.000000  2002.000000    6.000000    2.000000  2018.000000"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only relevant peaks features \n",
    "peaks_features = ['peakid', 'heightm', 'himal', 'region', 'open', 'unlisted', 'trekking', 'trekyear', \n",
    "                  'restrict', 'phost', 'pstatus', 'pyear']\n",
    "\n",
    "# New dataframe with only selected columns\n",
    "peaks = peaks_csv[peaks_features]\n",
    "\n",
    "# Inspect the data\n",
    "peaks.head()\n",
    "peaks.info()\n",
    "peaks.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values for 'restrict' will be negated when introducing 'expeditions.csv'. Example, a peak's open status ('open' = True) changes from False on year 'openyear', when the Nepal government approved the peak.\n",
    "\n",
    "In the same way 'restrict' indicates the year the 'open' status changed between closed or open, however in this case the year and open/closed inside the 'restrict' column will have to be used to create a new column indicating when the peak's status changed. If the new column, called 'openyear' contains a date (year), the 'open' value will simply switch between True/False.\n",
    "\n",
    "The missing values for column 'pyear', or the first ascent year, will be determined from 'expedition.csv' where the fist expedition date for the specific peak took place.\n",
    "\n",
    "The column 'trekyear' is type float due to the NaN values. Notice 'trekyear' has a minimum value of 20, which can't be right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN       439\n",
       "1978.0     18\n",
       "2002.0     10\n",
       "20.0        1\n",
       "Name: trekyear, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'trekyear'\n",
    "peaks['trekyear'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to the one entry with year '20', if you looking at the value counts, the only other option for an entry is the year 1978, but the entry already starts with '20'. Therefore assume the entry should have been the year 2002.\n",
    "\n",
    "In any case, with only 2 years for which these entries exits, 1978 and 2002, one cannot assume that the features, 'trekking' and 'trekyear' will affect a significant difference. In addition, the Nepalese government does not include trekking peaks in their statistical reports and analysis. Therefore, 'trekking' and 'trekyear' will be ommited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['peakid', 'heightm', 'himal', 'region', 'open', 'unlisted', 'restrict', 'phost', 'pstatus', 'pyear'], dtype='object')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleting columns 'trekking' and 'trekyear'.\n",
    "peaks = peaks.drop(['trekking', 'trekyear'], axis=1, errors='ignore')\n",
    "peaks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>restrict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   open        restrict\n",
       "0  True  Opened in 2014\n",
       "1  True  Opened in 2014\n",
       "3  True  Opened in 2002\n",
       "4  True  Opened in 2002\n",
       "5  True  Opened in 2002"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>restrict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 2002 as trekking peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 1997; converted to trekking peak in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2013?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 2002, delisted in 2013?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 2002 as trekking peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2014 as Hillary Peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2014 as Tenzing Peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 2002 as trekking peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>False</td>\n",
       "      <td>Opened in 2002 as trekking peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>True</td>\n",
       "      <td>Opened in 2014 (as Khang Karpo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      open                                           restrict\n",
       "40   False                    Opened in 2002 as trekking peak\n",
       "53   False  Opened in 1997; converted to trekking peak in ...\n",
       "142   True                                    Opened in 2013?\n",
       "146  False                  Opened in 2002, delisted in 2013?\n",
       "219  False                    Opened in 2002 as trekking peak\n",
       "301   True                     Opened in 2014 as Hillary Peak\n",
       "302   True                     Opened in 2014 as Tenzing Peak\n",
       "310  False                    Opened in 2002 as trekking peak\n",
       "319  False                    Opened in 2002 as trekking peak\n",
       "377   True                    Opened in 2014 (as Khang Karpo)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'open' and 'restrict'\n",
    "\n",
    "# Exclude all NaN's and retain DataFrame\n",
    "inspect = peaks[peaks['restrict'].notnull()][['open', 'restrict']]\n",
    "# Only select rows that contain values in 'restrict' \n",
    "inspect_open = inspect[inspect['restrict'].str.contains('Open')]\n",
    "\n",
    "# Create pattern that identifies \"Opened in <year>\" from column 'restrict'.\n",
    "pattern = re.compile('Opened in \\d{4}$')\n",
    "mask = inspect_open['restrict'].apply(lambda x : True if bool(pattern.match(x)) else False)\n",
    "inspect_open[mask].head()\n",
    "\n",
    "# Now only show the rows that don't match the pattern \"Opened in <year>\" for further inspection.\n",
    "inspect_open[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, where 'open' = False, the 'restrict' value only refers to trekking status, thus those values can set to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peakid</th>\n",
       "      <th>heightm</th>\n",
       "      <th>himal</th>\n",
       "      <th>region</th>\n",
       "      <th>open</th>\n",
       "      <th>unlisted</th>\n",
       "      <th>restrict</th>\n",
       "      <th>phost</th>\n",
       "      <th>pstatus</th>\n",
       "      <th>pyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CHEK</td>\n",
       "      <td>6121</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CHRI</td>\n",
       "      <td>5550</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>HUNK</td>\n",
       "      <td>6119</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>KYAZ</td>\n",
       "      <td>6151</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>NREK</td>\n",
       "      <td>6159</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>OMBG</td>\n",
       "      <td>6340</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    peakid  heightm  himal  region   open  unlisted restrict  phost  pstatus   pyear\n",
       "40    CHEK     6121     19       2  False     False     None      4        2  2005.0\n",
       "53    CHRI     5550     12       2  False     False     None      1        2  1965.0\n",
       "146   HUNK     6119     12       2  False      True     None      1        2  2012.0\n",
       "219   KYAZ     6151     12       2  False     False     None      1        2  2002.0\n",
       "310   NREK     6159     12       2  False     False     None      1        2     NaN\n",
       "319   OMBG     6340     12       2  False     False     None      1        2  1960.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "NaN                                                   204\n",
       "Opened in 2014                                         97\n",
       "Opened in 2002                                         92\n",
       "Opened in 2003                                         40\n",
       "Opened in 1997                                          4\n",
       "Opened in 2001                                          4\n",
       "One permit for Churen Himal's three summits             3\n",
       "Converted to trekking peak in 2002                      3\n",
       "Requires permit for Jobo Rinjang                        3\n",
       "Requires permit for Annapurna I                         2\n",
       "Peak entirely within China                              2\n",
       "Requires permit for Nuptse                              2\n",
       "Opened in 2014 (as Khang Karpo)                         1\n",
       "Requires permit for Gimmigela Chuli                     1\n",
       "Opened in 2016                                          1\n",
       "Opened in 2014 as Hillary Peak                          1\n",
       "Opened in 2013?                                         1\n",
       "Requires Jannu permit                                   1\n",
       "Delisted in 2014                                        1\n",
       "Requires permit for Lachama Chuli                       1\n",
       "Opened in 2014 as Tenzing Peak                          1\n",
       "Closed                                                  1\n",
       "One permit for Kanjiroba's north and south summits      1\n",
       "Requires permit for Amphu I                             1\n",
       "Name: restrict, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find indices where 'open' = False AND 'restrict' does not match the pattern\n",
    "val_to_remove = inspect_open[~mask]\n",
    "#val_to_remove[val_to_remove['open'] == False]\n",
    "\n",
    "# Find only these calues in peaks DataFrame\n",
    "idx = val_to_remove[val_to_remove['open'] == False].index\n",
    "#peaks.loc[idx]\n",
    "\n",
    "# Change these values to NaN\n",
    "peaks['restrict'].loc[idx] = None\n",
    "\n",
    "# Check new correct values\n",
    "peaks.loc[idx]\n",
    "\n",
    "# Look for the other 'Opened in ...' entries and \n",
    "peaks['restrict'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Opened in 2014                     97\n",
       "Opened in 2002                     92\n",
       "Opened in 2003                     40\n",
       "Opened in 2001                      4\n",
       "Opened in 1997                      4\n",
       "Opened in 2014 as Tenzing Peak      1\n",
       "Opened in 2014 as Hillary Peak      1\n",
       "Opened in 2014 (as Khang Karpo)     1\n",
       "Opened in 2013?                     1\n",
       "Opened in 2016                      1\n",
       "Name: restrict, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the year values can be retreived and saved as float in a new column.\n",
    "# Why not int? Pandas float works better when series contains NaN's\n",
    "\n",
    "# Inspect 'open' and 'restrict' again after some values changed in 'restrict'\n",
    "# Exclude all NaN's and retain DataFrame\n",
    "inspect = peaks[peaks['restrict'].notnull()][['open', 'restrict']]\n",
    "# Only select rows that contain values in 'restrict' \n",
    "inspect_open = inspect[inspect['restrict'].str.contains('Open')]\n",
    "\n",
    "# New values\n",
    "inspect_open['restrict'].value_counts()\n",
    "\n",
    "# Get year information only\n",
    "pattern2 = re.compile('\\d{4}')\n",
    "\n",
    "# Add peaks column 'openyear' and remove column 'restrict'\n",
    "peaks['openyear'] = inspect_open['restrict'].apply(lambda x : re.findall(pattern2, x)[0])\n",
    "peaks = peaks.drop('restrict', axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peakid</th>\n",
       "      <th>heightm</th>\n",
       "      <th>himal</th>\n",
       "      <th>region</th>\n",
       "      <th>open</th>\n",
       "      <th>unlisted</th>\n",
       "      <th>phost</th>\n",
       "      <th>pstatus</th>\n",
       "      <th>pyear</th>\n",
       "      <th>openyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACHN</td>\n",
       "      <td>6055</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGLE</td>\n",
       "      <td>6675</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAD</td>\n",
       "      <td>6814</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMOT</td>\n",
       "      <td>6393</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMPG</td>\n",
       "      <td>5630</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  peakid  heightm  himal  region  open  unlisted  phost  pstatus   pyear  openyear\n",
       "0   ACHN     6055     17       7  True     False      1        2  2015.0    2014.0\n",
       "1   AGLE     6675     19       2  True     False      1        1     NaN    2014.0\n",
       "2   AMAD     6814     12       2  True     False      1        2  1961.0       NaN\n",
       "3   AMOT     6393      3       5  True     False      1        1     NaN    2002.0\n",
       "4   AMPG     5630     12       2  True     False      1        2  1953.0    2002.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Data columns (total 10 columns):\n",
      "peakid      468 non-null object\n",
      "heightm     468 non-null int64\n",
      "himal       468 non-null int64\n",
      "region      468 non-null int64\n",
      "open        468 non-null bool\n",
      "unlisted    468 non-null bool\n",
      "phost       468 non-null int64\n",
      "pstatus     468 non-null int64\n",
      "pyear       325 non-null float64\n",
      "openyear    242 non-null float64\n",
      "dtypes: bool(2), float64(2), int64(5), object(1)\n",
      "memory usage: 30.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert columns 'openyear' to float\n",
    "peaks['openyear'] = peaks['openyear'].astype(float)\n",
    "\n",
    "# Review data\n",
    "peaks.head()\n",
    "peaks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert these columns from bool to binary\n",
    "to_bin = ['open', 'unlisted']\n",
    "peaks[to_bin] = peaks[to_bin].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Data columns (total 10 columns):\n",
      "peakid      468 non-null object\n",
      "heightm     468 non-null int64\n",
      "himal       468 non-null category\n",
      "region      468 non-null category\n",
      "open        468 non-null int8\n",
      "unlisted    468 non-null int8\n",
      "phost       468 non-null category\n",
      "pstatus     468 non-null category\n",
      "pyear       325 non-null float64\n",
      "openyear    242 non-null float64\n",
      "dtypes: category(4), float64(2), int64(1), int8(2), object(1)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Lastly, convert himal, region, phost and pstatus to category\n",
    "peaks[['himal', 'region', 'phost', 'pstatus']] = peaks[['himal', 'region', 'phost', 'pstatus']].astype('category')\n",
    "peaks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'peaks' data set is complete. Columns with NaN values 'pyear' and 'openyear' will be completed when joined with the 'epedition' data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expedition dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9959, 65)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9959 entries, 0 to 9958\n",
      "Data columns (total 65 columns):\n",
      "expid         9959 non-null object\n",
      "peakid        9959 non-null object\n",
      "year          9959 non-null int64\n",
      "season        9959 non-null int64\n",
      "host          9959 non-null int64\n",
      "route1        9806 non-null object\n",
      "route2        307 non-null object\n",
      "route3        30 non-null object\n",
      "route4        5 non-null object\n",
      "nation        9959 non-null object\n",
      "leaders       9935 non-null object\n",
      "sponsor       9139 non-null object\n",
      "success1      9959 non-null bool\n",
      "success2      9959 non-null bool\n",
      "success3      9959 non-null bool\n",
      "success4      9959 non-null bool\n",
      "ascent1       2719 non-null object\n",
      "ascent2       101 non-null object\n",
      "ascent3       11 non-null object\n",
      "ascent4       4 non-null object\n",
      "claimed       9959 non-null bool\n",
      "disputed      9959 non-null bool\n",
      "countries     3224 non-null object\n",
      "approach      4677 non-null object\n",
      "bcdate        9959 non-null object\n",
      "smtdate       9959 non-null object\n",
      "smttime       4273 non-null float64\n",
      "smtdays       9959 non-null int64\n",
      "totdays       9959 non-null int64\n",
      "termdate      9959 non-null object\n",
      "termreason    9959 non-null int64\n",
      "termnote      4308 non-null object\n",
      "highpoint     9959 non-null int64\n",
      "traverse      9959 non-null bool\n",
      "ski           9959 non-null bool\n",
      "parapente     9959 non-null bool\n",
      "camps         9959 non-null int64\n",
      "rope          9959 non-null int64\n",
      "totmembers    9959 non-null int64\n",
      "smtmembers    9959 non-null int64\n",
      "mdeaths       9959 non-null int64\n",
      "tothired      9959 non-null int64\n",
      "smthired      9959 non-null int64\n",
      "hdeaths       9959 non-null int64\n",
      "nohired       9959 non-null bool\n",
      "o2used        9959 non-null bool\n",
      "o2none        9959 non-null bool\n",
      "o2climb       9959 non-null bool\n",
      "o2descent     9959 non-null bool\n",
      "o2sleep       9959 non-null bool\n",
      "o2medical     9959 non-null bool\n",
      "o2taken       9959 non-null bool\n",
      "o2unkwn       9959 non-null bool\n",
      "othersmts     1965 non-null object\n",
      "campsites     9632 non-null object\n",
      "accidents     3411 non-null object\n",
      "achievment    913 non-null object\n",
      "agency        8394 non-null object\n",
      "comrte        9959 non-null bool\n",
      "stdrte        9959 non-null bool\n",
      "primrte       9959 non-null bool\n",
      "primmem       9959 non-null bool\n",
      "primref       9959 non-null bool\n",
      "primid        651 non-null object\n",
      "chksum        9959 non-null int64\n",
      "dtypes: bool(23), float64(1), int64(16), object(25)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load expeditions as 'xpd' for short\n",
    "xpd = pd.read_csv('expeditions.csv')\n",
    "\n",
    "# Inspect the total entries and non-null values\n",
    "xpd.shape\n",
    "xpd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referring to the 'Himalayan Database Guide.pdf', the following features will not be included:\n",
    "\n",
    "route2-4 - Since 'route1' has significantly less null values compared to 'route2/3/4', only 'route1' will be used. There is also little information on 'route2/3/4' information in the documentation.\n",
    "\n",
    "sponsor - Looking at it's value_counts, there are too many NaN values and sponsors with the most counts are independent, non-descript entries.\n",
    "\n",
    "success1-4 - Aggregate success[1-4] to new column xpd_success. If any attempt at summit 'success[1-4]' was successful, then 'xpd_success' will be true.\n",
    "\n",
    "ascent1-4 - For the same reason as 'route2-4', 'ascent1-4' has not contain enough data and according to the documentation, these numbers are not maintained for recent ascends of some peaks.\n",
    "\n",
    "claimed - This describes disputed successes which, according to the documentation, is not included as successes in statistical reports and analysis. Value_counts only give 30 True values, which does not affect 'success1'.\n",
    "\n",
    "disputed - This describes the disputed nature of this summit, but does not affect the outcome of 'success1'.\n",
    "\n",
    "countries - Too many NaN values. This data will be captured by the members dataset.\n",
    "\n",
    "approach - Too many NaN values.\n",
    "\n",
    "bcdate - The base camp date, 'bcdate', will be discounted by the summit date, as more relevant.\n",
    "\n",
    "smttime, smtdays, totdays, termdate - Too many Null values.\n",
    "\n",
    "termnote, highpoint - Not relevant.\n",
    "\n",
    "o2unkwn - Only 21 True values. The other oxygen related columns covers the 21 unknown oxygen use columns.\n",
    "\n",
    "othersmts, campsites, accidents, achievement - Detailed descriptive information. Cannot be used.\n",
    "\n",
    "stdrte - This is the 8000m standard route. Not applicable to all peaks then.\n",
    "\n",
    "primrte, primmem, primref, primid, chksum - Not relevent. Database related fields.\n",
    "\n",
    "\n",
    "Output (Y) - Feature 'termreason' will be used as the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9959, 35)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['expid', 'peakid', 'year', 'season', 'host', 'route1', 'nation', 'leaders', 'success1', 'success2',\n",
       "       'success3', 'success4', 'smtdate', 'termreason', 'traverse', 'ski', 'parapente', 'camps', 'rope',\n",
       "       'totmembers', 'smtmembers', 'mdeaths', 'tothired', 'smthired', 'hdeaths', 'nohired', 'o2used',\n",
       "       'o2none', 'o2climb', 'o2descent', 'o2sleep', 'o2medical', 'agency', 'comrte', 'stdrte'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the following features\n",
    "drop_columns = ['route2', 'route3', 'route4', 'sponsor', 'ascent1', 'ascent2', 'ascent3', 'ascent4', \n",
    "                'claimed', 'disputed', 'countries', 'approach', 'bcdate', 'smttime', 'smtdays', 'totdays',\n",
    "                'termdate', 'termnote', 'highpoint', 'o2unkwn', 'o2taken', 'othersmts', 'campsites', 'accidents', \n",
    "                'achievment', 'primrte', 'primmem', 'primref', 'primid', 'chksum']\n",
    "\n",
    "# Drop the columns not needed\n",
    "xpd.drop(drop_columns, inplace=True, axis=1)\n",
    "\n",
    "xpd.shape\n",
    "xpd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate columns 'success[1-4]' to new column 'xpd_success'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# New column 'xpd_success' from 'success[1-4]'\n",
    "xpd['xpd_success'] = 1\n",
    "xpd['xpd_success'] = xpd['xpd_success'].where((xpd['success1'] == True) | (xpd['success2'] == True) | \\\n",
    "                                           (xpd['success3'] == True) | (xpd['success4'] == True), 0)\n",
    "\n",
    "# Drop columns 'success[1-4]'\n",
    "drop_columns = ['success1', 'success2', 'success3', 'success4']\n",
    "xpd.drop(drop_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further data cleaning follows.\n",
    "\n",
    "Note: For 'nation' former names of countries have to be used. Example, expeditions from Eastern Bloc countries before 1993 were recorded as USSR. It is not possible now to tell from which post-1993 country they belong to. Therefore post-1993 expeditions for these countries will be grouped under USSR. \n",
    "\n",
    "Czech Republic and Slovakia will change to Czechoslovakia.\n",
    "Belarus, Estonia, Georgia, Kazakhstan, Latvia, Lithuania, Russia, Ukrain and Uzbekistan will change to USSR.\n",
    "Exception; 'W Germany' will change to 'Germany'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean the data for the remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SW Ridge                                               0.140526\n",
       "S Col-SE Ridge                                         0.108913\n",
       "NW side                                                0.103100\n",
       "N Col-NE Ridge                                         0.065776\n",
       "NE Face                                                0.062921\n",
       "NE Ridge                                               0.040587\n",
       "W Face                                                 0.039670\n",
       "SE Ridge                                               0.037120\n",
       "Makalu La-NW Ridge                                     0.025189\n",
       "N Face                                                 0.022027\n",
       "NW Ridge                                               0.019172\n",
       "SW Face                                                0.017438\n",
       "W Ridge                                                0.017234\n",
       "S Face                                                 0.012951\n",
       "S Ridge                                                0.011728\n",
       "N Ridge                                                0.008260\n",
       "SE Face                                                0.007342\n",
       "W Ridge-W Face from N                                  0.006221\n",
       "E Ridge                                                0.005813\n",
       "N Col-N Face                                           0.005099\n",
       "SE Face-E Ridge                                        0.004691\n",
       "NE Spur-N Ridge                                        0.004181\n",
       "E Face                                                 0.003875\n",
       "NW Face                                                0.002753\n",
       "E Ridge from S                                         0.002753\n",
       "N Col-N Ridge-N Face                                   0.002651\n",
       "W Ridge-W Face from S                                  0.002549\n",
       "Reconnaissance                                         0.002346\n",
       "S side                                                 0.002346\n",
       "N Face (Dutch Rib)                                     0.002142\n",
       "                                                         ...   \n",
       "NE Face?                                               0.000102\n",
       "NW Ridge to N Peak                                     0.000102\n",
       "N Face-N Ridge (to 6400m)                              0.000102\n",
       "SE Ridge (intended)                                    0.000102\n",
       "From SE Barun Glacier                                  0.000102\n",
       "SW Face-SE Ridge                                       0.000102\n",
       "S Face (right side via Couloir)                        0.000102\n",
       "Chinese route                                          0.000102\n",
       "W Face of N Col                                        0.000102\n",
       "S Ridge from south                                     0.000102\n",
       "N Face (1980 German rte)                               0.000102\n",
       "SE Ridge-SW Summit                                     0.000102\n",
       "N Face-Kwangde Shar-Main Smt (up); NE Ridge (down)     0.000102\n",
       "NE Ridge-NW Face-NW Ridge-N Smt (up); N Face (down)    0.000102\n",
       "S Face (variation of Bonington rte)                    0.000102\n",
       "W Face (to 7000m)                                      0.000102\n",
       "N Ridge up; W side down                                0.000102\n",
       "E Face of S Ridge                                      0.000102\n",
       "W Face-NNW Ridge                                       0.000102\n",
       "S Face (from 6800m to right of Bonington rte)          0.000102\n",
       "SW Face (to 8450m)                                     0.000102\n",
       "N Pillar from west via east glacier                    0.000102\n",
       "NE Face (variation at start)                           0.000102\n",
       "Eastern most buttress of E Face                        0.000102\n",
       "S side-S Ridge (to E Peak) (to 7250m)                  0.000102\n",
       "W Ridge-W Face from N (Tichy var)                      0.000102\n",
       "Arete on S Face-Pt 7726 on Smt Ridge                   0.000102\n",
       "W Face of Lunag I                                      0.000102\n",
       "W Ridge from S Face                                    0.000102\n",
       "NW Face (right side of N Pillar)                       0.000102\n",
       "Name: route1, Length: 1219, dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert these columns to category\n",
    "to_cat = ['season', 'host', 'termreason']\n",
    "for col in to_cat:\n",
    "    xpd[col] = xpd[col].astype('category')\n",
    "    \n",
    "xpd['route1'].value_counts('dropna=False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert these columns from bool to binary\n",
    "to_bin = ['traverse', 'ski', 'parapente', 'nohired', 'o2used', 'o2none', 'o2climb', 'o2descent', \n",
    "          'o2sleep', 'o2medical', 'comrte', 'stdrte']\n",
    "xpd[to_bin] = xpd[to_bin].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'route1' has 153 NaN. Change each NaN value to the index number as a random name. \n",
    "def replace_nan_with_diff_object_val(df, column):\n",
    "    \"\"\" Replace NaN values in a column with different object values in DataFrame df\"\"\"\n",
    "    df[column].loc[df[column].isnull()] = \\\n",
    "        df[column].loc[df[column].isnull()].apply(lambda x: random.randint(0, 1000))\n",
    "\n",
    "replace_nan_with_diff_object_val(xpd, 'route1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'nation' includes  older names of countries in the previous Eastern Bloc. For consistency, change \n",
    "# new country names to older ones. \n",
    "xpd['nation'] = xpd['nation'].replace(to_replace='W Germany/Iran', value='Germany/Iran')\n",
    "xpd['nation'] = xpd['nation'].replace(to_replace='W Germany', value='Germany')\n",
    "\n",
    "current_name = ['Czech Republic', 'Slovakia']\n",
    "for name in current_name:\n",
    "    xpd['nation'] = xpd['nation'].replace(to_replace=name, value='Czechoslovakia')\n",
    "    \n",
    "current_name = ['Croatia', 'Macedonia', 'Serbia',' Slovenia']\n",
    "for name in current_name:\n",
    "    xpd['nation'] = xpd['nation'].replace(to_replace=name, value='Yugoslavia')\n",
    "    \n",
    "current_name = ['Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Latvia', 'Lithuania', 'Russia', \n",
    "                'Ukrain', 'Uzbekistan']\n",
    "for name in current_name:\n",
    "    xpd['nation'] = xpd['nation'].replace(to_replace=name, value='USSR')\n",
    "    \n",
    "# leaders has 24 NaN. Change each NaN value to the index number as a random name.\n",
    "replace_nan_with_diff_object_val(xpd, 'leaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# smtdate get month data only as category. There are 634 NaNs. \n",
    "# Extract month information\n",
    "xpd['smtmonth'] = xpd['smtdate'].str.split('/').str[1]\n",
    "# Convert to float in order to calcualte mean and replace NaNs with the mean\n",
    "xpd['smtmonth'] = xpd['smtmonth'].astype(float)\n",
    "xpd['smtmonth'] = xpd['smtmonth'].fillna(xpd['smtmonth'].mean())\n",
    "# Convert back to int to drop the decimals, then convert to category\n",
    "xpd['smtmonth'] = xpd['smtmonth'].astype(int).astype('category')\n",
    "# Drop the 'smtdate' column - not needed.\n",
    "xpd.drop('smtdate', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tothired - (nohired = True) indicates true zero for 'tothired'. Find the Falses and allocate \n",
    "# mean values. There are 260 missing values.\n",
    "xpd['tothired'].loc[idx] = xpd['tothired'].mean().round()\n",
    "xpd['tothired'] = xpd['tothired'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# agency has 1565 NaN. \n",
    "replace_nan_with_diff_object_val(xpd, 'agency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9959 entries, 0 to 9958\n",
      "Data columns (total 32 columns):\n",
      "expid          9959 non-null object\n",
      "peakid         9959 non-null object\n",
      "year           9959 non-null int64\n",
      "season         9959 non-null category\n",
      "host           9959 non-null category\n",
      "route1         9959 non-null object\n",
      "nation         9959 non-null object\n",
      "leaders        9959 non-null object\n",
      "termreason     9959 non-null category\n",
      "traverse       9959 non-null int8\n",
      "ski            9959 non-null int8\n",
      "parapente      9959 non-null int8\n",
      "camps          9959 non-null int64\n",
      "rope           9959 non-null int64\n",
      "totmembers     9959 non-null int64\n",
      "smtmembers     9959 non-null int64\n",
      "mdeaths        9959 non-null int64\n",
      "tothired       9959 non-null int64\n",
      "smthired       9959 non-null int64\n",
      "hdeaths        9959 non-null int64\n",
      "nohired        9959 non-null int8\n",
      "o2used         9959 non-null int8\n",
      "o2none         9959 non-null int8\n",
      "o2climb        9959 non-null int8\n",
      "o2descent      9959 non-null int8\n",
      "o2sleep        9959 non-null int8\n",
      "o2medical      9959 non-null int8\n",
      "agency         9959 non-null object\n",
      "comrte         9959 non-null int8\n",
      "stdrte         9959 non-null bool\n",
      "xpd_success    9959 non-null int64\n",
      "smtmonth       9959 non-null category\n",
      "dtypes: bool(1), category(4), int64(10), int8(11), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect cleaned xpd dataframe\n",
    "xpd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 468 entries, 0 to 467\n",
      "Data columns (total 10 columns):\n",
      "peakid      468 non-null object\n",
      "heightm     468 non-null int64\n",
      "himal       468 non-null category\n",
      "region      468 non-null category\n",
      "open        468 non-null int8\n",
      "unlisted    468 non-null int8\n",
      "phost       468 non-null category\n",
      "pstatus     468 non-null category\n",
      "pyear       325 non-null float64\n",
      "openyear    242 non-null float64\n",
      "dtypes: category(4), float64(2), int64(1), int8(2), object(1)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Now look at peaks again\n",
    "peaks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use xpd DataFrame to clean 'pyear'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 380 entries, 0 to 379\n",
      "Data columns (total 10 columns):\n",
      "peakid      380 non-null object\n",
      "heightm     380 non-null int64\n",
      "himal       380 non-null category\n",
      "region      380 non-null category\n",
      "open        380 non-null int8\n",
      "unlisted    380 non-null int8\n",
      "phost       380 non-null category\n",
      "pstatus     380 non-null category\n",
      "pyear       380 non-null int32\n",
      "openyear    166 non-null float64\n",
      "dtypes: category(4), float64(1), int32(1), int64(1), int8(2), object(1)\n",
      "memory usage: 27.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# For xpd, find min(year) for peakid\n",
    "peak_open_year = xpd.groupby('peakid')['year'].min()\n",
    "\n",
    "# Merge this new Series with peaks DF\n",
    "peaks_merge = pd.merge(peaks, peak_open_year, on=['peakid'])\n",
    "\n",
    "# Replace NaN values in 'pyear' with values in 'year'\n",
    "peaks_merge['pyear'].loc[peaks_merge['pyear'] != peaks_merge['pyear']] = peaks_merge['year']\n",
    "  \n",
    "# Drop 'year' as it is not needed anymore\n",
    "peaks_merge.drop('year', inplace=True, axis=1)\n",
    "\n",
    "# Now that there are no NaNs, change 'pyear' type to int\n",
    "peaks_merge['pyear'] = peaks_merge['pyear'].astype(int)\n",
    "\n",
    "# Review\n",
    "peaks_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge peaks and expeditions, then clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9959, 41)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9959 entries, 0 to 9958\n",
      "Data columns (total 41 columns):\n",
      "expid          9959 non-null object\n",
      "peakid         9959 non-null object\n",
      "year           9959 non-null int64\n",
      "season         9959 non-null category\n",
      "host           9959 non-null category\n",
      "route1         9959 non-null object\n",
      "nation         9959 non-null object\n",
      "leaders        9959 non-null object\n",
      "termreason     9959 non-null category\n",
      "traverse       9959 non-null int8\n",
      "ski            9959 non-null int8\n",
      "parapente      9959 non-null int8\n",
      "camps          9959 non-null int64\n",
      "rope           9959 non-null int64\n",
      "totmembers     9959 non-null int64\n",
      "smtmembers     9959 non-null int64\n",
      "mdeaths        9959 non-null int64\n",
      "tothired       9959 non-null int64\n",
      "smthired       9959 non-null int64\n",
      "hdeaths        9959 non-null int64\n",
      "nohired        9959 non-null int8\n",
      "o2used         9959 non-null int8\n",
      "o2none         9959 non-null int8\n",
      "o2climb        9959 non-null int8\n",
      "o2descent      9959 non-null int8\n",
      "o2sleep        9959 non-null int8\n",
      "o2medical      9959 non-null int8\n",
      "agency         9959 non-null object\n",
      "comrte         9959 non-null int8\n",
      "stdrte         9959 non-null bool\n",
      "xpd_success    9959 non-null int64\n",
      "smtmonth       9959 non-null category\n",
      "heightm        9959 non-null int64\n",
      "himal          9959 non-null category\n",
      "region         9959 non-null category\n",
      "open           9959 non-null int8\n",
      "unlisted       9959 non-null int8\n",
      "phost          9959 non-null category\n",
      "pstatus        9959 non-null category\n",
      "pyear          9959 non-null int32\n",
      "openyear       575 non-null float64\n",
      "dtypes: bool(1), category(8), float64(1), int32(1), int64(11), int8(13), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "xpd_peak = pd.merge(xpd, peaks_merge, on='peakid')\n",
    "xpd_peak.shape\n",
    "xpd_peak.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each expedition the peak 'open' status might be different depending on the year when the Nepalese government approved the peak for official expeditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9959 entries, 0 to 9958\n",
      "Data columns (total 40 columns):\n",
      "expid          9959 non-null object\n",
      "peakid         9959 non-null object\n",
      "year           9959 non-null int64\n",
      "season         9959 non-null category\n",
      "host           9959 non-null category\n",
      "route1         9959 non-null object\n",
      "nation         9959 non-null object\n",
      "leaders        9959 non-null object\n",
      "termreason     9959 non-null category\n",
      "traverse       9959 non-null int8\n",
      "ski            9959 non-null int8\n",
      "parapente      9959 non-null int8\n",
      "camps          9959 non-null int64\n",
      "rope           9959 non-null int64\n",
      "totmembers     9959 non-null int64\n",
      "smtmembers     9959 non-null int64\n",
      "mdeaths        9959 non-null int64\n",
      "tothired       9959 non-null int64\n",
      "smthired       9959 non-null int64\n",
      "hdeaths        9959 non-null int64\n",
      "nohired        9959 non-null int8\n",
      "o2used         9959 non-null int8\n",
      "o2none         9959 non-null int8\n",
      "o2climb        9959 non-null int8\n",
      "o2descent      9959 non-null int8\n",
      "o2sleep        9959 non-null int8\n",
      "o2medical      9959 non-null int8\n",
      "agency         9959 non-null object\n",
      "comrte         9959 non-null int8\n",
      "stdrte         9959 non-null bool\n",
      "xpd_success    9959 non-null int64\n",
      "smtmonth       9959 non-null category\n",
      "heightm        9959 non-null int64\n",
      "himal          9959 non-null category\n",
      "region         9959 non-null category\n",
      "open           9959 non-null int8\n",
      "unlisted       9959 non-null int8\n",
      "phost          9959 non-null category\n",
      "pstatus        9959 non-null category\n",
      "pyear          9959 non-null int32\n",
      "dtypes: bool(1), category(8), int32(1), int64(11), int8(13), object(6)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# If the expedition 'year' is less than 'openyear', the 'open' value is False (0), else if the expedition 'year' is \n",
    "# more than 'openyear', the 'open' value is True (1). If 'openyear' is NaN, the 'open' status remains unchanged.\n",
    "\n",
    "# Keep 'pyear' value, unless NaN - then use 'year' value\n",
    "for idx, row in xpd_peak.iterrows():\n",
    "    # If a float value does not equal itself, it must be NaN\n",
    "    if not row['openyear'] != row['openyear']:\n",
    "        if row['year'] < row['openyear']:\n",
    "            xpd_peak['open'].loc[idx] = 0\n",
    "        else:\n",
    "            xpd_peak['open'].loc[idx] = 1\n",
    "\n",
    "# Drop 'openyear' as it is not needed anymore\n",
    "xpd_peak.drop('openyear', inplace=True, axis=1)\n",
    "            \n",
    "xpd_peak.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xpd_peak DataFrame now contains the completed and clean data or Peaks and Expeditions.\n",
    "\n",
    "Next the members dataset will be cleaned and then merged with the xpd_peak DataFrame. \n",
    "\n",
    "To recap: Each peak consists of many expeditions. Each expedition consists of many members. The completed dataset will contain data peak-expedition-members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 5. Members dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65534, 85)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65534 entries, 0 to 65533\n",
      "Data columns (total 85 columns):\n",
      "expid         65534 non-null object\n",
      "membid        65534 non-null int64\n",
      "peakid        65534 non-null object\n",
      "myear         65534 non-null int64\n",
      "mseason       65534 non-null int64\n",
      "fname         65430 non-null object\n",
      "lname         64627 non-null object\n",
      "sex           65532 non-null object\n",
      "age           65534 non-null int64\n",
      "birthdate     65534 non-null object\n",
      "yob           60481 non-null float64\n",
      "calcage       65534 non-null int64\n",
      "citizen       65524 non-null object\n",
      "status        65518 non-null object\n",
      "residence     60765 non-null object\n",
      "occupation    49428 non-null object\n",
      "leader        65534 non-null bool\n",
      "deputy        65534 non-null bool\n",
      "bconly        65534 non-null bool\n",
      "nottobc       65534 non-null bool\n",
      "support       65534 non-null bool\n",
      "disabled      65534 non-null bool\n",
      "hired         65534 non-null bool\n",
      "sherpa        65534 non-null bool\n",
      "tibetan       65534 non-null bool\n",
      "msuccess      65534 non-null bool\n",
      "mclaimed      65534 non-null bool\n",
      "mdisputed     65534 non-null bool\n",
      "msolo         65534 non-null bool\n",
      "mtraverse     65534 non-null bool\n",
      "mski          65534 non-null bool\n",
      "mparapente    65534 non-null bool\n",
      "mspeed        65534 non-null bool\n",
      "mhighpt       65534 non-null bool\n",
      "mperhighpt    65534 non-null int64\n",
      "msmtdate1     65534 non-null object\n",
      "msmtdate2     65534 non-null object\n",
      "msmtdate3     65534 non-null object\n",
      "msmttime1     16728 non-null float64\n",
      "msmttime2     146 non-null float64\n",
      "msmttime3     4 non-null float64\n",
      "mroute1       65534 non-null int64\n",
      "mroute2       65534 non-null int64\n",
      "mroute3       65534 non-null int64\n",
      "mascent1      65534 non-null int64\n",
      "mascent2      65534 non-null int64\n",
      "mascent3      65534 non-null int64\n",
      "mo2used       65534 non-null bool\n",
      "mo2none       65534 non-null bool\n",
      "mo2climb      65534 non-null bool\n",
      "mo2descent    65534 non-null bool\n",
      "mo2sleep      65534 non-null bool\n",
      "mo2medical    65534 non-null bool\n",
      "mo2note       10459 non-null object\n",
      "death         65534 non-null bool\n",
      "deathdate     65534 non-null object\n",
      "deathtime     535 non-null float64\n",
      "deathtype     65534 non-null int64\n",
      "deathhgtm     65534 non-null int64\n",
      "deathclass    65534 non-null int64\n",
      "msmtbid       65534 non-null int64\n",
      "msmtterm      65534 non-null int64\n",
      "hcn           65534 non-null int64\n",
      "mchksum       65534 non-null int64\n",
      "host          65534 non-null int64\n",
      "comrte        65534 non-null bool\n",
      "stdrte        65534 non-null bool\n",
      "route1        64889 non-null object\n",
      "route2        2830 non-null object\n",
      "route3        440 non-null object\n",
      "route4        157 non-null object\n",
      "nation        65534 non-null object\n",
      "leaders       65513 non-null object\n",
      "sponsor       61670 non-null object\n",
      "termreason    65534 non-null int64\n",
      "totmembers    65534 non-null int64\n",
      "smtmembers    65534 non-null int64\n",
      "mdeaths       65534 non-null int64\n",
      "tothired      65534 non-null int64\n",
      "nohired       65534 non-null bool\n",
      "smthired      65534 non-null int64\n",
      "hdeaths       65534 non-null int64\n",
      "bcdate        65534 non-null object\n",
      "pkname        65534 non-null object\n",
      "heightm       65534 non-null int64\n",
      "dtypes: bool(28), float64(5), int64(28), object(24)\n",
      "memory usage: 30.2+ MB\n"
     ]
    }
   ],
   "source": [
    "memb = pd.read_csv('members.csv')\n",
    "memb.shape\n",
    "memb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Referring to Himalayan Database Guide, irrelevent information such as first name, last name and information already contained in the combined xpd_peak DataFrame will be dropped. \n",
    "\n",
    "Features that remain will undergo further analysis for suitability.\n",
    "\n",
    "Quick features analysis revealed the following:\n",
    "- Age values are null, use calcage instead. 3098 values where age is 0, so use average age for those rows\n",
    "- Summit information, msmtdate/msmttime/mroute/mascent[1-3] is incomplete\n",
    "- Only 1,029 deaths from a total of 65,534 members (1.57%) occurred, therefore all death related information dropped\n",
    "- 'nottobc' Members that did not reach base camp. This information is aready captured in overall member success and can be droppped.\n",
    "- 'support' describe the few members (233) that travelled just beyond base camp to in a support role (often used for photographers and advisors for women’s expeditions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65301, 29)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 65301 entries, 0 to 65533\n",
      "Data columns (total 29 columns):\n",
      "expid         65301 non-null object\n",
      "peakid        65301 non-null object\n",
      "sex           65299 non-null object\n",
      "calcage       65301 non-null int64\n",
      "citizen       65291 non-null object\n",
      "status        65285 non-null object\n",
      "residence     60565 non-null object\n",
      "occupation    49248 non-null object\n",
      "leader        65301 non-null bool\n",
      "deputy        65301 non-null bool\n",
      "bconly        65301 non-null bool\n",
      "disabled      65301 non-null bool\n",
      "hired         65301 non-null bool\n",
      "sherpa        65301 non-null bool\n",
      "tibetan       65301 non-null bool\n",
      "msuccess      65301 non-null bool\n",
      "msolo         65301 non-null bool\n",
      "mtraverse     65301 non-null bool\n",
      "mski          65301 non-null bool\n",
      "mparapente    65301 non-null bool\n",
      "mspeed        65301 non-null bool\n",
      "mo2used       65301 non-null bool\n",
      "mo2none       65301 non-null bool\n",
      "mo2climb      65301 non-null bool\n",
      "mo2descent    65301 non-null bool\n",
      "mo2sleep      65301 non-null bool\n",
      "mo2medical    65301 non-null bool\n",
      "msmtterm      65301 non-null int64\n",
      "nation        65301 non-null object\n",
      "dtypes: bool(19), int64(2), object(8)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# List of colmns to drop\n",
    "col_to_drop = ['membid', 'myear', 'mseason', 'fname', 'lname', 'age', 'birthdate', 'yob', 'mclaimed', \n",
    "               'mdisputed', 'mhighpt', 'mperhighpt', 'msmtdate1', 'msmtdate2', 'msmtdate3', 'msmttime1', \n",
    "               'msmttime2', 'msmttime3', 'mroute1', 'mroute2', 'mroute3', 'mascent1', 'mascent2', 'mascent3', \n",
    "               'mo2note', 'death', 'deathdate', 'deathtime', 'deathtype', 'deathhgtm', 'deathclass', 'msmtbid' ,'hcn', \n",
    "               'mchksum', 'host', 'comrte', 'stdrte', 'route1', 'route2', 'route3', 'route4', 'leaders', 'sponsor', \n",
    "               'termreason', 'totmembers', 'smtmembers', 'mdeaths', 'tothired', 'nohired', 'smthired', \n",
    "               'hdeaths', 'bcdate', 'pkname', 'heightm', 'nottobc']\n",
    "# Exclude features above\n",
    "memb.drop(col_to_drop, inplace=True, axis=1)\n",
    "\n",
    "# Exclude support members and drop the column\n",
    "memb = memb[memb['support'] != True]\n",
    "memb.drop('support', inplace=True, axis=1)\n",
    "\n",
    "memb.shape\n",
    "memb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Clean the new memb dataset features 'calcage', 'residence', 'occupation', 'sex' and 'status'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for mean age per expedition\n",
    "dict_age_exp = dict(memb.groupby('expid')['calcage'].mean().apply(lambda x: int(round(x))))\n",
    "\n",
    "# Find indices where calcage = 0\n",
    "calcage_zeroes_idx = memb[memb['calcage'] == 0][['expid', 'calcage']].index\n",
    "\n",
    "# Set the zero calcage values to the expid. This will next be replaced using .map\n",
    "memb['calcage'].loc[calcage_zeroes_idx] = memb.loc[calcage_zeroes_idx]['expid']\n",
    "# Now set the expid values to the mean of each expedition\n",
    "memb['calcage'].loc[calcage_zeroes_idx] = memb['calcage'].loc[calcage_zeroes_idx].map(dict_age_exp)\n",
    "\n",
    "# Replace ages 0 - 5 with average age\n",
    "age_mean = int(round(memb['calcage'].mean()))\n",
    "for age in np.arange(0,6):\n",
    "    memb['calcage'] = memb['calcage'].replace(age, age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                 4736\n",
       "Tokyo, Japan                                        1234\n",
       "Seoul, S Korea                                       912\n",
       "Beding, Dolakha                                      744\n",
       "Phortse, Khumbu                                      681\n",
       "Pangboche, Khumbu                                    653\n",
       "Khumjung, Khumbu                                     627\n",
       "London, England                                      531\n",
       "Chamonix, Haute-Savoie, France                       521\n",
       "Thami, Khumbu                                        493\n",
       "Kharikhola, Solukhumbu                               411\n",
       "Seattle, Washington                                  346\n",
       "Paris, France                                        343\n",
       "Boulder, Colorado                                    306\n",
       "Moscow, Russia                                       282\n",
       "Barcelona, Spain                                     264\n",
       "Madrid, Spain                                        262\n",
       "Warsaw, Poland                                       248\n",
       "Daegu (Taegu), S Korea                               233\n",
       "Walung, Makalu-9, Makalu-Barun                       225\n",
       "Namche Bazar, Khumbu                                 223\n",
       "Vienna, Austria                                      194\n",
       "Sapporo, Hokkaido, Japan                             184\n",
       "Munich, Bavaria, Germany                             177\n",
       "Busan (Pusan), S Korea                               172\n",
       "Osaka, Japan                                         161\n",
       "Yilajung, Khumbu                                     156\n",
       "Sofia, Bulgaria                                      152\n",
       "Thamo, Khumbu                                        151\n",
       "Pamplona, Navarra, Spain                             148\n",
       "                                                    ... \n",
       "Hualein Shien, Taiwan                                  1\n",
       "Thuringia, Germany                                     1\n",
       "Hayama, Kanagawa, Japan                                1\n",
       "Vastervik, Sweden                                      1\n",
       "Sonchamp, Yvelines, France                             1\n",
       "Montana, Valais, Switzerland                           1\n",
       "Tweedbank, Galashiels, Scotland                        1\n",
       "Sotillo de la Adarda, Avila, Spain                     1\n",
       "St. Esteve, Vaucluse, France                           1\n",
       "Varces, Isere, France                                  1\n",
       "Miles, Illinois                                        1\n",
       "Zentsuji, Kanagawa, Japan                              1\n",
       "Ashgabad, Turkmenistan                                 1\n",
       "Prien am Chiemsee, Bavaria, W Germany                  1\n",
       "Cornudella de Montsant, Tarragona, Spain               1\n",
       "Saint Amand, Manche, France                            1\n",
       "Arkesden, Essex, England                               1\n",
       "Shyzenji, Shizuoka, Japan                              1\n",
       "Sanuma, Miyagi, Japan                                  1\n",
       "Kathmandu & Hazelbrook, Sydney, NSW, Australia         1\n",
       "Forel, Aargau, Switzerland                             1\n",
       "Leutkirch im Allgau, Baden-Wuerttemberg, Germany       1\n",
       "Wattenheim, Hesse, Germany                             1\n",
       "Plock, Poland                                          1\n",
       "Verzuolo, Cuneo, Italy                                 1\n",
       "Wynau, Bern, Switzerland                               1\n",
       "Amposta, Tarragona, Spain                              1\n",
       "Kaprun, Austria                                        1\n",
       "Essendon, Victoria, Australia                          1\n",
       "Flexbourg, Bas-Rhin, France                            1\n",
       "Name: residence, Length: 12884, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect 'residence'\n",
    "memb['residence'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Japan                                      6304\n",
       "France                                     4506\n",
       "Khumbu                                     3802\n",
       "Spain                                      3114\n",
       "England                                    3072\n",
       "S Korea                                    2868\n",
       "Italy                                      2646\n",
       "Solukhumbu                                 2576\n",
       "Switzerland                                2560\n",
       "Germany                                    2268\n",
       "Austria                                    1954\n",
       "Makalu-Barun                               1680\n",
       "China                                      1474\n",
       "India                                      1465\n",
       "Australia                                  1235\n",
       "Poland                                     1228\n",
       "Colorado                                   1163\n",
       "Russia                                     1089\n",
       "California                                 1020\n",
       "Dolakha                                     953\n",
       "Washington                                  937\n",
       "W Germany                                   808\n",
       "New Zealand                                 677\n",
       "UK                                          662\n",
       "Netherlands                                 629\n",
       "Czech Republic                              527\n",
       "Scotland                                    507\n",
       "Slovenia                                    506\n",
       "Yugoslavia                                  501\n",
       "Norway                                      472\n",
       "                                           ... \n",
       "New Guinea                                    1\n",
       "UK/USA                                        1\n",
       "Japan (born Solukhumbu)                       1\n",
       "Massachuestts                                 1\n",
       "New Zealand and Kathmandu                     1\n",
       "Turkmenistan                                  1\n",
       "Boulder Colorado                              1\n",
       "NY                                            1\n",
       "Cayman Islands                                1\n",
       "Channal Island                                1\n",
       "Syanja                                        1\n",
       "Russia (but currently living in Moscow)       1\n",
       "Monitoba                                      1\n",
       "Corsica                                       1\n",
       "Saudia Arabia                                 1\n",
       "Kotang                                        1\n",
       "Fera (Junbesi). Solukhumbu                    1\n",
       "Togo                                          1\n",
       "Luzembourg                                    1\n",
       "Bolzanom Italy                                1\n",
       "Kobe,Japan                                    1\n",
       "Malawi                                        1\n",
       "Papua New Guinea                              1\n",
       "Bheri                                         1\n",
       "Patan                                         1\n",
       "Ilam                                          1\n",
       "Sankhuwasabha                                 1\n",
       "Myagdi district                               1\n",
       "Lousianna                                     1\n",
       " Italy                                        1\n",
       "Name: residence, Length: 411, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For NaNs, assume expidition 'nation' as member 'residence'\n",
    "memb['residence'].loc[memb['residence'] != memb['residence']] = memb['nation']\n",
    "\n",
    "# Only use last word to extract the country\n",
    "memb['residence'] = memb['residence'].apply(lambda x: str(x).split(', ')[-1])\n",
    "\n",
    "# Inspect\n",
    "memb['residence'].value_counts(dropna=False)\n",
    "\n",
    "# Don't need 'nation' anymore\n",
    "memb.drop('nation', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "As there are enough members from provinces in Nepal and states in the US, these values are not grouped into countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change Current country name to former name for consistency\n",
    "# 'resident' includes  older names of countries in the previous Eastern Bloc. For consistency, change \n",
    "# new country names to older ones. \n",
    "memb['residence'] = memb['residence'].replace(to_replace='W Germany/Iran', value='Germany/Iran')\n",
    "memb['residence'] = memb['residence'].replace(to_replace='W Germany', value='Germany')\n",
    "memb['residence'] = memb['residence'].replace(to_replace='England', value='UK')\n",
    "\n",
    "current_name = ['Czech Republic', 'Slovakia']\n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='Czechoslovakia')\n",
    "    \n",
    "current_name = ['Croatia', 'Macedonia', 'Serbia',' Slovenia']\n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='Yugoslavia')\n",
    "    \n",
    "current_name = ['Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Latvia', 'Lithuania', 'Russia', \n",
    "                'Ukrain', 'Uzbekistan']\n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='USSR')\n",
    "    \n",
    "current_name = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "                \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "                \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "                \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "                \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "                \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "                \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "                \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]    \n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='USA')\n",
    "    \n",
    "current_name = ['a', 'Khumbu', 'Solukhumbu', 'Makalu-Barun', 'Dolakha', 'Okhaldhunga', 'Taplejung', \n",
    "                'Khotang', 'Kathmandu', 'Gorkha', 'Rasuwa', 'Gandaki Zone', 'Sindhupalchowk', \n",
    "                'Tanahun', 'Kaski', 'Bagmati Zone', 'Lumbini Zone', 'Kavre', 'Gandaki', 'Ramechap', \n",
    "                'Ramechhap', 'Lamjung', 'Pokhara', 'India (from Solukhumbu', 'Gulmi', 'Solukhumbu (', \n",
    "                'Dhading', 'Bhojpur', 'Dang', 'India (born in Solukhumbu', 'Kosi Zone', \n",
    "                'Kabre (now Dhulikel', 'Jiri', 'Janakpur', 'Chitwan', 'Udayapur', 'Baglung', \n",
    "                'Myagdi', 'Janakpur Zone', 'Sunsari', 'Upper Makalu-Barun', 'Kailali', 'Mahakali', \n",
    "                'Nuwakot', 'Palpa', 'Dhaulagiri Zone', 'Khumbu', 'Rapti', 'Mechi Zone', 'Bagmati', \n",
    "                'Jhapa', 'Kanchanpur', 'Dailekh', 'Sarlahi', 'Morang', 'Rukum', 'Lumbini', 'East Nepal', \n",
    "                'Lalitpur', 'Makalu-Barun (now Darjeeling', 'Myadi', 'Mahakali Zone', 'Bardiya', \n",
    "                'Narayani Zone', 'Sindhupalchok', 'Trachigmo', 'Sindhuli', 'Narayan Zone', \n",
    "                'Japan (born Solukhumbu', 'Patan', 'Tatopani (Kodari', 'Syanja', 'Langtang-3', 'Ilam', \n",
    "                'Tokha', 'Mustang', 'Mundu', 'Bhaktapur', 'Solukhumbu (between Chaurikharka', 'Butwal', \n",
    "                'Dharan', 'Myagdi district', 'Tehrathum', 'Taktod', 'Rapti Zone', 'Dhankuta', 'Bheri', \n",
    "                'Dharamasthali', 'Janakpur (currently living in Biratnagar', 'Fera (Junbesi', 'Bojpur', \n",
    "                'Pachthar', 'Ktm', 'Humla', 'Bardia', 'Narayani', 'Manang', 'Syangja', 'Fidim District', \n",
    "                'Nangda La (near Trachigmo', 'Village near Pokhara', 'Kotang', 'Saptari', \n",
    "                'Sankhuwasabha', 'India (born Makalu-Barun', 'Bhadrutar Village', 'Okhakdhunga', \n",
    "                'Dolpa', 'Solukbumbu']\n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='Nepal')\n",
    "\n",
    "current_name = ['Alberta', 'British Columbia', 'Manitoba', 'New Brunswick', 'Newfoundland and Labrador', \n",
    "                'Nova Scotia', 'Ontario', 'Prince Edward Island', 'Quebec', 'Saskatchewan', \n",
    "                'Northwest Territories', 'Nunavut', 'Yukon'] \n",
    "for name in current_name:\n",
    "    memb['residence'] = memb['residence'].replace(to_replace=name, value='Canada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Filter other mistakes in 'residence'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nepal                                10415\n",
       "Japan                                 6306\n",
       "USA                                   6045\n",
       "France                                4506\n",
       "UK                                    3735\n",
       "Spain                                 3114\n",
       "Germany                               3077\n",
       "S Korea                               2869\n",
       "Italy                                 2650\n",
       "Switzerland                           2561\n",
       "Austria                               1957\n",
       "USSR                                  1835\n",
       "China                                 1474\n",
       "India                                 1465\n",
       "Australia                             1238\n",
       "Poland                                1228\n",
       "Czechoslovakia                        1063\n",
       "Canada                                 960\n",
       "New Zealand                            678\n",
       "Yugoslavia                             672\n",
       "Netherlands                            629\n",
       "Scotland                               507\n",
       "Slovenia                               506\n",
       "Norway                                 472\n",
       "Belgium                                403\n",
       "Iran                                   294\n",
       "Ukraine                                291\n",
       "Sweden                                 285\n",
       "Mexico                                 237\n",
       "Bulgaria                               207\n",
       "                                     ...  \n",
       "Pennsylvnia                              1\n",
       "Chinese Mountaineering Team              1\n",
       "Namibia                                  1\n",
       "Slovenia Yugoslavia                      1\n",
       "SLovenia                                 1\n",
       "Massachuestts                            1\n",
       "Fera (Junbesi                            1\n",
       "Pennslvania                              1\n",
       "New Guinea                               1\n",
       "Brabant                                  1\n",
       "Sarthe France                            1\n",
       "Montreal Quebec                          1\n",
       "Channal Island                           1\n",
       "North Chungcheong S Korea                1\n",
       "Malawi                                   1\n",
       "Spain                                    1\n",
       "Papua New Guinea                         1\n",
       "Lousianna                                1\n",
       "Australiz                                1\n",
       "Bolzanom Italy                           1\n",
       "Luzembourg                               1\n",
       "Washington                               1\n",
       "Washington                               1\n",
       "Monitoba                                 1\n",
       "Togo                                     1\n",
       "Solukhumbu (between Chaurikharka         1\n",
       "Georgia                                  1\n",
       "Saudia Arabia                            1\n",
       "Corsica                                  1\n",
       "India (living in Darjeeling              1\n",
       "Name: residence, Length: 228, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix space before country name\n",
    "memb['residence'].loc[memb['residence'].str.contains(r\"^ \\w*\")] = \\\n",
    "    memb['residence'][memb['residence'].str.contains(r\"^ \\w*\")].str.strip()\n",
    "\n",
    "# Replace values with a name in brackets '( )' and use first word to extract the country only, or names\n",
    "# split by characters like ?, /, &.\n",
    "memb['residence'].loc[memb['residence'].str.contains('[\\)/&]')] = \\\n",
    "    memb['residence'][memb['residence'].str.contains('[\\)/&]')].str.split('[?)/&]').apply(lambda x: x[0])\n",
    "\n",
    "# Replace values with a komma. Example City,Country.\n",
    "memb['residence'].loc[memb['residence'].str.contains(',')] = \\\n",
    "    memb['residence'][memb['residence'].str.contains(',')].str.split(',').apply(lambda x: x[-1])\n",
    "\n",
    "# Inspect\n",
    "memb['residence'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memb['residence'].value_counts(dropna=False)[memb['residence'].value_counts(dropna=False) == 1])\n",
    "len(memb['residence'].value_counts(dropna=False)[memb['residence'].value_counts(dropna=False) == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "There are 117 + 41 = 158 entries that have single or double occurances which contains mostly spelling errors. These values could be edited individually, but it should not make a big difference to overall performance. To be revisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill in NaN values as before\n",
    "replace_nan_with_diff_object_val(memb, 'occupation')\n",
    "replace_nan_with_diff_object_val(memb, 'status')\n",
    "replace_nan_with_diff_object_val(memb, 'citizen')\n",
    "\n",
    "# Set the 2 NaN values to male. Asumption as majority of climbers are male (90.2%)\n",
    "memb['sex'].loc[memb['sex'].isnull()] = 'M' \n",
    "\n",
    "# Change data types where applicable\n",
    "memb['sex'] = memb['sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Change Current country name to former name for consistency\n",
    "# 'resident' includes  older names of countries in the previous Eastern Bloc. For consistency, change \n",
    "# new country names to older ones. \n",
    "memb['citizen'] = memb['citizen'].replace(to_replace='W Germany/Iran', value='Germany/Iran')\n",
    "memb['citizen'] = memb['citizen'].replace(to_replace='W Germany', value='Germany')\n",
    "\n",
    "current_name = ['Czech Republic', 'Slovakia']\n",
    "for name in current_name:\n",
    "    memb['citizen'] = memb['citizen'].replace(to_replace=name, value='Czechoslovakia')\n",
    "    \n",
    "current_name = ['Croatia', 'Macedonia', 'Serbia',' Slovenia']\n",
    "for name in current_name:\n",
    "    memb['citizen'] = memb['citizen'].replace(to_replace=name, value='Yugoslavia')\n",
    "    \n",
    "current_name = ['Belarus', 'Estonia', 'Georgia', 'Kazakhstan', 'Latvia', 'Lithuania', 'Russia', \n",
    "                'Ukrain', 'Uzbekistan']\n",
    "for name in current_name:\n",
    "    memb['citizen'] = memb['citizen'].replace(to_replace=name, value='USSR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['stdrte'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-2278800f519d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[1;34m'msolo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mtraverse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mski'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mparapente'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mspeed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mo2used'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mo2none'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mo2climb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           'mo2descent', 'mo2sleep', 'mo2medical', 'stdrte']\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmemb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_bin\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mto_bin\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\springboard_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\springboard_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\springboard_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\springboard_env\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['stdrte'] not in index\""
     ]
    }
   ],
   "source": [
    "# Convert these columns from bool to binary\n",
    "to_bin = ['leader', 'deputy', 'bconly', 'disabled', 'hired', 'sherpa', 'tibetan', 'msuccess', \n",
    "          'msolo', 'mtraverse', 'mski', 'mparapente', 'mspeed', 'mo2used', 'mo2none', 'mo2climb', \n",
    "          'mo2descent', 'mo2sleep', 'mo2medical']\n",
    "memb[to_bin] = memb[to_bin].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "memb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members dataset is now complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xpd_peak.shape\n",
    "memb.shape\n",
    "\n",
    "df_complete = pd.merge(memb, xpd_peak, on=['peakid', 'expid'], how='left')\n",
    "\n",
    "df_complete.shape\n",
    "df_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save completed DataFrame \n",
    "df_complete.to_csv('DF_Himalayas_Expeditions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
